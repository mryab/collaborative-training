{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mryab/collaborative-training/blob/main/colab_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdQIcM112KfI"
      },
      "source": [
        "<center><img src=\"https://i.imgur.com/FHMoW3N.png\" width=360px><br><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Collaborative training <sup>v0.9 alpha</sup></b></center>\n",
        "\n",
        "\n",
        "This notebook will use local or colab GPU to help train ALBERT-large collaboratively. Your instance will compute gradients and exchange them with a bunch of volunteers around the world. We explain how it works at the bottom. But for now, please run all cells :)\n",
        "\n",
        "To start training, you will need to login to your huggingface account, please fill in the prompts as in the example below (replace `robot-bengali` with your username):\n",
        "\n",
        "![img](https://i.imgur.com/txuWbJi.png)\n",
        "\n",
        "Please do not run colab notebooks from multiple google accounts: google doesn't like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnUf-OajJt8S",
        "outputId": "a7880dd8-3395-4131-ec40-e442d284e7e4"
      },
      "source": [
        "experiment_name = \"bengali_MAIN\"\n",
        "hivemind_version = \"bengali-main-run\"\n",
        "collaborative_training_version = \"main\" \n",
        "%env HF_EXPERIMENT_ID 15\n",
        "\n",
        "!echo \"Installing dependencies...\"\n",
        "!pip install git+https://github.com/learning-at-home/hivemind.git@{hivemind_version} >> install.log 2>&1\n",
        "!git clone https://github.com/mryab/collaborative-training -b {collaborative_training_version} >> install.log 2>&1\n",
        "%cd ./collaborative-training\n",
        "!pip install -r requirements.txt >> install.log 2>&1\n",
        "\n",
        "from shlex import quote\n",
        "import torch\n",
        "from huggingface_auth import authorize_with_huggingface\n",
        "from runner import run_with_logging\n",
        "\n",
        "assert torch.cuda.is_available(), \"GPU device not found. If running in colab, please retry in a few minutes.\"\n",
        "device_name = torch.cuda.get_device_name(0)\n",
        "microbatch_size = 4 if 'T4' in device_name or 'P100' in device_name else 1\n",
        "print(f\"Running with device {device_name}, local batch size = {microbatch_size}\")\n",
        "\n",
        "authorizer = authorize_with_huggingface()\n",
        "\n",
        "command = f\"\"\"ulimit -n 4096 && HIVEMIND_THREADS=256 \\\n",
        " HF_USERNAME={quote(authorizer.username)} HF_PASSWORD={quote(authorizer.password)} python ./run_trainer.py --client_mode \\\n",
        " --initial_peers 13.59.206.122:31337 18.190.156.209:31337 {authorizer.coordinator_ip}:{authorizer.coordinator_port} \\\n",
        " --averaging_expiration 10 --statistics_expiration 120 \\\n",
        " --batch_size_lead 400 --per_device_train_batch_size {microbatch_size} --gradient_accumulation_steps 1 \\\n",
        " --logging_first_step --logging_steps 100 --run_name {quote(authorizer.username)} \\\n",
        " --output_dir ./outputs --overwrite_output_dir --logging_dir ./logs \\\n",
        " --experiment_prefix {quote(experiment_name)} --seed 42\"\"\"\n",
        "run_with_logging(command, authorizer.coordinator_ip, wandb_login=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: HF_EXPERIMENT_ID=15\n",
            "Installing dependencies...\n",
            "/content/collaborative-training\n",
            "Running with device Tesla K80, local batch size = 1\n",
            "HuggingFace username: yhn112\n",
            "HuggingFace password: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021/05/12 10:58:11.493][INFO][root._join_experiment:104] Access for user yhn112 has been granted until 2021-06-02 10:58:11.442467 UTC\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 10:58:14.138215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n",
            "[2021/05/12 10:58:18.736][INFO][__main__.main:213] Using 3 initial peers: ['13.59.206.122:31337', '18.190.156.209:31337', '18.219.141.99:31337']\n",
            "[2021/05/12 10:58:18.738][WARN][__main__.setup_logging:43] Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "[2021/05/12 10:58:18.738][INFO][__main__.setup_logging:50] Training/evaluation parameters AlbertTrainingArguments(output_dir='./outputs', overwrite_output_dir=True, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.00176, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=1000000, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=5000, logging_dir='./logs', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=True, logging_steps=100, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=2, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O2', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='yhn112', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, mp_parameters='', seq_length=512, clamp_value=10000.0)\n",
            "Downloading:   0%|          | 0.00/685 [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 685/685 [00:00<00:00, 504kB/s]\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.5.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "Downloading:   0%|          | 0.00/1.72M [00:00<?, ?B/s]\n",
            "Downloading:   2%|▏         | 36.9k/1.72M [00:00<00:06, 253kB/s]\n",
            "Downloading:  11%|█▏        | 197k/1.72M [00:00<00:04, 325kB/s]\n",
            "Downloading:  37%|███▋      | 643k/1.72M [00:00<00:02, 450kB/s]\n",
            "Downloading: 100%|██████████| 1.72M/1.72M [00:00<00:00, 3.41MB/s]\n",
            "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 321/321 [00:00<00:00, 247kB/s]\n",
            "Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 467/467 [00:00<00:00, 354kB/s]\n",
            "[2021/05/12 10:58:21.884][INFO][__main__.get_model:56] Checkpoint dir outputs, contents []\n",
            "[2021/05/12 10:58:21.885][INFO][__main__.get_model:63] Training from scratch\n",
            "punkt not found. downloading...\n",
            "Downloading:   0%|          | 0.00/2.38k [00:00<?, ?B/s]\n",
            "Downloading: 100%|██████████| 2.38k/2.38k [00:00<00:00, 1.70MB/s]\n",
            "Downloading:   0%|          | 0.00/5.58k [00:00<?, ?B/s]\n",
            "Downloading: 14.7kB [00:00, 6.93MB/s]\n",
            "Downloading:   0%|          | 0.00/359k [00:00<?, ?B/s]\n",
            "Downloading: 3.07MB [00:00, 89.6MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:894: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  FutureWarning,\n",
            "wandb: Currently logged in as: yhn112 (use `wandb login --relogin` to force relogin)\n",
            "2021-05-12 10:58:46.012295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "wandb: Tracking run with wandb version 0.10.30\n",
            "wandb: Syncing run yhn112\n",
            "wandb: ⭐️ View project at https://wandb.ai/learning-at-home/Worker_logs\n",
            "wandb: 🚀 View run at https://wandb.ai/learning-at-home/Worker_logs/runs/1zboi1ah\n",
            "wandb: Run data is saved locally in /content/collaborative-training/wandb/run-20210512_105843-1zboi1ah\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "[2021/05/12 10:58:48.763][INFO][__main__.on_train_begin:119] Loading state from peers\n",
            "[2021/05/12 10:58:50.455][INFO][client.averaging._load_state_from_peers:439] Downloading parameters from peer ipv4:18.217.128.94:33703\n",
            "[2021/05/12 10:58:58.567][INFO][client.averaging._load_state_from_peers:455] Finished downloading state from ipv4:18.217.128.94:33703\n",
            "[2021/05/12 10:59:42.463][ERROR][client.averaging._step:275] Averager caught AllreduceException('Averaging step failed: could not find a group.')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hivemind/client/averaging/__init__.py\", line 260, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group.\")\n",
            "hivemind.client.averaging.allreduce.AllreduceException: Averaging step failed: could not find a group.\n",
            "[2021/05/12 10:59:42.470][INFO][optim.collaborative.step:221] Skipped averaging: averaging round failed with AllreduceException('Averaging step failed: could not find a group.').\n",
            "[2021/05/12 10:59:43.088][INFO][__main__.on_step_end:145] Step 23\n",
            "[2021/05/12 10:59:43.088][INFO][__main__.on_step_end:146] Your current contribution: 0 samples\n",
            "[2021/05/12 10:59:43.088][INFO][__main__.on_step_end:148] Local loss: 11.2638\n",
            "[2021/05/12 11:00:11.660][INFO][optim.collaborative.step:219] Averaged tensors successfully with 3 peers\n",
            "[2021/05/12 11:00:11.736][INFO][__main__.on_step_end:145] Step 24\n",
            "[2021/05/12 11:00:11.736][INFO][__main__.on_step_end:146] Your current contribution: 10 samples\n",
            "[2021/05/12 11:00:11.737][INFO][__main__.on_step_end:148] Local loss: 11.12069090909091\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "[2021/05/12 11:01:12.984][ERROR][client.averaging._step:275] Averager caught AllreduceException('Averaging step failed: could not find a group.')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hivemind/client/averaging/__init__.py\", line 260, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group.\")\n",
            "hivemind.client.averaging.allreduce.AllreduceException: Averaging step failed: could not find a group.\n",
            "[2021/05/12 11:01:12.987][INFO][optim.collaborative.step:221] Skipped averaging: averaging round failed with AllreduceException('Averaging step failed: could not find a group.').\n",
            "[2021/05/12 11:01:13.064][INFO][__main__.on_step_end:145] Step 25\n",
            "[2021/05/12 11:01:13.064][INFO][__main__.on_step_end:146] Your current contribution: 34 samples\n",
            "[2021/05/12 11:01:13.064][INFO][__main__.on_step_end:148] Local loss: 11.164063999999998\n",
            "[2021/05/12 11:01:57.498][ERROR][client.averaging._step:275] Averager caught AllreduceException('Averaging step failed: could not find a group.')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hivemind/client/averaging/__init__.py\", line 260, in _step\n",
            "    raise AllreduceException(\"Averaging step failed: could not find a group.\")\n",
            "hivemind.client.averaging.allreduce.AllreduceException: Averaging step failed: could not find a group.\n",
            "[2021/05/12 11:01:57.504][INFO][optim.collaborative.step:221] Skipped averaging: averaging round failed with AllreduceException('Averaging step failed: could not find a group.').\n",
            "[2021/05/12 11:01:57.582][INFO][__main__.on_step_end:145] Step 26\n",
            "[2021/05/12 11:01:57.582][INFO][__main__.on_step_end:146] Your current contribution: 43 samples\n",
            "[2021/05/12 11:01:57.582][INFO][__main__.on_step_end:148] Local loss: 11.09516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93KCg3RZzEks"
      },
      "source": [
        "### What's up next?\n",
        "* Check the training progress on public learning curves: https://wandb.ai/learning-at-home/Main_metrics\n",
        "* Run a second GPU session with kaggle notebooks: https://www.kaggle.com/yhn112/collaborative-training-d87a28\n",
        "* View model checkpoints: https://huggingface.co/Upload/bengali-albert \n",
        "* See [this tutorial](https://github.com/learning-at-home/hivemind/tree/master/examples/albert) on how to start your own collaborative runs!\n",
        "\n",
        "\n",
        "_Co-created by [yhn112](https://github.com/yhn112), [leshanbog](https://github.com/leshanbog), [foksly](https://github.com/foksly) and [borzunov](https://github.com/borzunov) from [hivemind](https://github.com/learning-at-home/hivemind) (YSDA), [lhoestq](https://github.com/lhoestq), [SaulLu](https://github.com/SaulLu) and [stas00](https://github.com/stas00) from [huggingface](http://huggingface.co)_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUQ_j06kS6pb"
      },
      "source": [
        "### How it works\n",
        "\n",
        "Since peers can join and leave at any time, we can't use global [Ring All-Reduce](https://towardsdatascience.com/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da) for averaging: a single missing peer can break the entire protocol. Instead, peers dynamically assemble into small groups and run all-reduce within each group. Consider an example with 9 GPUs:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.imgur.com/QcD1mfG.png\" width=360px><br>\n",
        "The All-Reduce protocol within group can be Ring-AllReduce, but we use a simpler all-to-all algorithm known as butterfly-like all-reduce.<br>\n",
        "<img src=\"https://i.imgur.com/ewq3vS6.png\" width=380px><br>\n",
        "After each successful round, participants shuffle around and find new groups:<br>\n",
        "<img src=\"https://i.imgur.com/dexNCL3.png\" width=350px>\n",
        "\n",
        "If one of the peers fails to do his part, it will only affect his local group, and only for a single round.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/RBmElUi.png\" width=340px>\n",
        "\n",
        "Afterwards, peers from the failed group will find new groupmates according to the [moshpit algorithm](https://arxiv.org/abs/2103.03239).\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "If you want to learn more and even host your own collaborative experiments, take a look at the [hivemind library](https://github.com/learning-at-home/hivemind/) or the [Moshpit-SGD paper](https://arxiv.org/pdf/2103.03239.pdf).\n",
        "\n",
        "\n"
      ]
    }
  ]
}
